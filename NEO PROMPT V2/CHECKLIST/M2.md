```
# NeoPrompt Lifecycle — **Checkpoint M2: Design & Specification**
**File:** `docs/lifecycle/Checkpoint-2-Design-and-Specification.md`  
**Pattern:** Master doc + modular sub-artifacts under `docs/lifecycle/2-design/`  
**Note:** Copy embedded templates into sub-files now; also add copies to `/docs/templates/` for central reuse.

---

## 1) Purpose
Convert M1 research outputs into a formal, testable design. Define interfaces, schemas, failure modes, and operational envelopes that engineering can implement without ambiguity. All artifacts are machine-validated in CI.

---

## 2) Outcomes
- Architecture with data/control flows and dependency boundaries.
- OpenAPI spec and JSON Schemas for requests/responses and events.
- Interface contracts including SLAs, idempotency, and error taxonomy.
- Acceptance test spec routable by CI contract tests.
- Security, privacy, observability, versioning, scalability envelopes.
- Governance crosslinks back to M0/M1 artifacts.

---

## 3) Inputs & Constraints
- From M0: metrics JSON, risks, governance, dependencies.
- From M1: hypotheses, evaluation design, baseline JSON, data provenance, uncertainty plan, scope.
- Target runtime: local-first macOS; containerized later.
- Provider connector: OpenRouter; no secrets in repo.

---

## 4) Deliverables (files created in this checkpoint)
1. `docs/lifecycle/2-design/<FEATURE>_design.md` — System Design (rationale, diagrams, trade-offs)
2. `docs/lifecycle/2-design/<FEATURE>_openapi.yaml` — OpenAPI 3.1 spec
3. `docs/lifecycle/2-design/<FEATURE>_schemas/` — JSON Schemas
   - `request.schema.json`, `response.schema.json`, `event.schema.json` (as needed)
4. `docs/lifecycle/2-design/<FEATURE>_contracts.md` — Interface contracts (SLO/SLA, errors)
5. `docs/lifecycle/2-design/<FEATURE>_acceptance.yaml` — Acceptance tests (CI-runnable)
6. `docs/lifecycle/2-design/<FEATURE>_security.md` — Security & privacy requirements
7. `docs/lifecycle/2-design/<FEATURE>_observability.md` — Metrics, logs, traces
8. `docs/lifecycle/2-design/<FEATURE>_fmea.md` — Failure Modes & Effects Analysis
9. `docs/lifecycle/2-design/<FEATURE>_scalability.md` — QPS, limits, timeouts, resource budgets
10. `docs/lifecycle/2-design/<FEATURE>_review_checklist.md` — Design review checklist
11. `docs/lifecycle/2-design/<FEATURE>_decision_log.md` — Design decisions & alternatives

> During development, mirror templates to `/docs/templates/` for reuse.

---

## 5) Repository layout
```

/docs/lifecycle/

├─ Checkpoint-2-Design-and-Specification.md      # this file

└─ 2-design/

├─ _design.md

├─ _openapi.yaml

├─ _schemas/

│    ├─ request.schema.json

│    ├─ response.schema.json

│    └─ event.schema.json

├─ _contracts.md

├─ _acceptance.yaml

├─ _security.md

├─ _observability.md

├─ _fmea.md

├─ _scalability.md

├─ _review_checklist.md

└─ _decision_log.md

/docs/templates/ # keep synced copies of schemas and skeletons

```
---

## 6) Process (atomic)
1. **Branch**
   ```bash
   git checkout -b design/<FEATURE>
   mkdir -p docs/lifecycle/2-design/<FEATURE>_schemas docs/templates
```

2. **Author System Design** → <FEATURE>_design.md

3. **Draft OpenAPI** → <FEATURE>_openapi.yaml (lint with Spectral)

4. **Define JSON Schemas** → request/response/event.schema.json (validate with ajv)

5. **Write Contracts** → <FEATURE>_contracts.md (SLO, idempotency, errors)

6. **Acceptance Tests** → <FEATURE>_acceptance.yaml (traceable to contracts)

7. **Security** → <FEATURE>_security.md (authn/z, redaction, rate limits)

8. **Observability** → <FEATURE>_observability.md (metrics/logs/traces)

9. **FMEA** → <FEATURE>_fmea.md (failure modes, detection, mitigation)

10. **Scalability** → <FEATURE>_scalability.md (QPS, timeouts, memory caps)

11. **Review Checklist** → <FEATURE>_review_checklist.md (complete before PR)

12. **Decision Log** → <FEATURE>_decision_log.md

13. **Wire CI** → Spectral + ajv + basic contract-test dry-run

14. **PR** → title design(<FEATURE>): complete M2 pack; required reviewers Eng + QA (+ Research for alignment)

15. **Merge & Tag** → design-<FEATURE>-approved; issue moves to “Ready for M3”

---

## **7) Acceptance criteria**

- Design doc includes context, diagrams, alternatives, chosen approach.

- OpenAPI passes linter; schemas validate; acceptance tests load.

- Contracts define SLAs, error taxonomy, idempotency, backoff, retries.

- Security doc covers authn/z, data handling, logging redaction, rate limiting.

- Observability doc defines metric keys, log fields, trace spans.

- FMEA includes likelihood/impact/detection/mitigation and owners.

- Scalability doc enumerates QPS, payload sizes, concurrency, timeouts.

- Crosslinks to M0/M1 present; CI green; PR approved; tag created.

---

## **8) Security, privacy, compliance (M2 scope)**

- **Auth**: API key or OAuth2 bearer; no anonymous endpoints.

- **RBAC**: at least runner (execute), reader (metrics), admin (configs).

- **Input validation**: reject non-conforming JSON; schema-first.

- **Redaction**: never log raw prompts or tool args with secrets; hash probe IDs.

- **Rate limits**: default 60 r/min per API key; burst 10 r/s; 429 with backoff hints.

- **Secrets**: use env vars; no secrets in VCS; recommend 1Password/Vault.

- **Data retention**: store metrics only; TTL for run logs configurable; default 14 days.

- **Compliance**: respect dataset licenses; include license files in artifacts.

---

## **9) Observability requirements**

- **Metrics** (Prometheus-style):

  - eval_requests_total{feature,model} (counter)

  - eval_request_duration_ms{feature} (histogram; buckets)

  - reproducibility_rate{feature,model} (gauge)

  - robustness_delta{feature,model} (gauge)

  - errors_total{feature,error_class} (counter)

- **Logs**: JSONL with fields:

  - ts, level, feature_id, probe_id, model_id, provider, seed, dataset_version, commit_sha, elapsed_ms, status, error_class

- **Traces**: OpenTelemetry spans:

  - eval.request, eval.model_call, eval.score, attributes mirror log fields.

---

## **10) Versioning & compatibility**

- OpenAPI info.version = 1.0.0; bump minor for non-breaking additions.

- Schemas include $id and $schema; bump version fields on change.

- Backward compatibility: additive fields only; breaking change requires new path or v2.

---

## **11) Failure Modes & Fallbacks (FMEA stub)**

- Classes: timeout, schema_invalid, provider_error, rate_limited, tool_call_mismatch, storage_unavailable.

- Backoff: exponential with jitter; cap at 30s; max 3 retries for idempotent ops.

- Fallbacks:

  - If provider timeout → return 202 Accepted with poll token (optional) or deterministic error E-TIMEOUT.

  - If schema invalid → 400 with errors[].

  - If rate-limited → 429 with Retry-After.

---

## **12) Scalability envelope**

- QPS target (local): ≥ 50 eval/min; later: horizontally scalable.

- Concurrency: default 8; configurable.

- Payload: request ≤ 32 KB; response ≤ 64 KB.

- Timeouts: upstream provider 15s; total 20s P95; client retry budget 60s.

---

## **13) Embedded templates (copy to sub-files; also store in**

## **/docs/templates/**

## **)**

### **13.1 System Design —**

### **docs/lifecycle/2-design/<FEATURE>_design.md**

````
# System Design — <FEATURE>
version: 1.0.0

## Context & Goals
<Link to M0 intake, M1 evaluation design, hypotheses, baseline. Summarize what we are building and not building.>

## Architecture (Mermaid)
```mermaid
flowchart TD
    Client -->|HTTP JSON| API[<FEATURE> API]
    API --> VAL[Validator (JSON Schema)]
    API --> EXEC[Executor]
    EXEC -->|tool/model call| Provider[OpenRouter Connector]
    EXEC --> SCORE[Scorer]
    SCORE --> METRICS[Metrics Store]
    API --> STORE[Results Store]
````

## **Data Flow**

1. Request received → schema validation → execution plan → provider call → score → persist → respond.

## **Components**

- API: FastAPI (or similar)

- Validator: ajv server-side or pydantic-jsonschema

- Executor: orchestrates runs with fixed seeds

- Scorer: deterministic scorer; error taxonomy

- Storage: SQLite initially; interface allows later Postgres

- Observability: Prometheus, JSON logs, OTel

## **Alternatives**

- gRPC vs HTTP JSON: chose HTTP for simplicity; gRPC reserved for high-throughput later.

- Inline scoring vs async scoring queue: chose inline for local-first.

## **Chosen Approach**

- HTTP JSON, synchronous, deterministic scoring, minimal dependencies.

## **Risks & Mitigations**

- Provider latency variance → timeouts, retries, caching mocks

- Schema drift → schema versioning and CI contract tests

````
---

### 13.2 OpenAPI — `docs/lifecycle/2-design/<FEATURE>_openapi.yaml`
```yaml
openapi: 3.1.0
info:
  title: <FEATURE> Evaluation API
  version: 1.0.0
servers:
  - url: /api
paths:
  /<feature>/evaluate:
    post:
      summary: Run evaluation on a batch of probes
      operationId: evaluateFeature
      security:
        - ApiKeyAuth: []
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: "./<FEATURE>_schemas/request.schema.json"
      responses:
        "200":
          description: Evaluation results
          content:
            application/json:
              schema:
                $ref: "./<FEATURE>_schemas/response.schema.json"
        "400":
          description: Schema validation error
        "401":
          description: Unauthorized
        "429":
          description: Rate limited
        "500":
          description: Internal error
components:
  securitySchemes:
    ApiKeyAuth:
      type: apiKey
      in: header
      name: X-API-Key
````

---

### **13.3 JSON Schemas —**

### **docs/lifecycle/2-design/<FEATURE>_schemas/request.schema.json**

```
{
  "$id": "https://neoprompt.local/schemas/<FEATURE>/request.schema.json",
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "title": "<FEATURE> Request",
  "type": "object",
  "required": ["feature_id", "probes", "config"],
  "properties": {
    "feature_id": { "type": "string", "const": "<FEATURE>" },
    "probes": {
      "type": "array",
      "minItems": 1,
      "items": {
        "type": "object",
        "required": ["id", "prompt", "expected"],
        "properties": {
          "id": { "type": "string" },
          "prompt": { "type": "string", "minLength": 1 },
          "expected": {
            "type": "object",
            "required": ["tool", "args"],
            "properties": {
              "tool": { "type": "string" },
              "args": { "type": "object" }
            },
            "additionalProperties": false
          }
        },
        "additionalProperties": false
      }
    },
    "config": {
      "type": "object",
      "required": ["model_id", "provider", "seeds", "decoding"],
      "properties": {
        "model_id": { "type": "string" },
        "provider": { "type": "string" },
        "seeds": {
          "type": "array",
          "minItems": 1,
          "items": { "type": "integer" }
        },
        "decoding": {
          "type": "object",
          "required": ["temperature", "top_p"],
          "properties": {
            "temperature": { "type": "number" },
            "top_p": { "type": "number" }
          },
          "additionalProperties": false
        }
      },
      "additionalProperties": false
    }
  },
  "additionalProperties": false
}
```

#### **docs/lifecycle/2-design/<FEATURE>_schemas/response.schema.json**

```
{
  "$id": "https://neoprompt.local/schemas/<FEATURE>/response.schema.json",
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "title": "<FEATURE> Response",
  "type": "object",
  "required": ["feature_id", "model_id", "metrics", "by_probe"],
  "properties": {
    "feature_id": { "type": "string" },
    "model_id": { "type": "string" },
    "metrics": {
      "type": "object",
      "required": ["reproducibility_rate", "latency_p95_ms"],
      "properties": {
        "reproducibility_rate": { "type": "number" },
        "latency_p95_ms": { "type": "number" },
        "robustness_delta": { "type": "number" }
      },
      "additionalProperties": true
    },
    "by_probe": {
      "type": "array",
      "items": {
        "type": "object",
        "required": ["id", "status", "elapsed_ms"],
        "properties": {
          "id": { "type": "string" },
          "status": { "type": "string", "enum": ["ok", "error"] },
          "elapsed_ms": { "type": "number" },
          "error_class": { "type": "string" }
        },
        "additionalProperties": false
      }
    }
  },
  "additionalProperties": false
}
```

#### **docs/lifecycle/2-design/<FEATURE>_schemas/event.schema.json**

####  **(optional)**

```
{
  "$id": "https://neoprompt.local/schemas/<FEATURE>/event.schema.json",
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "title": "<FEATURE> Event",
  "type": "object",
  "required": ["ts", "feature_id", "event", "payload"],
  "properties": {
    "ts": { "type": "string" },
    "feature_id": { "type": "string" },
    "event": { "type": "string" },
    "payload": { "type": "object" }
  }
}
```

---

### **13.4 Interface Contracts —**

### **docs/lifecycle/2-design/<FEATURE>_contracts.md**

```
# Interface Contracts — <FEATURE>
version: 1.0.0

## Functional
- Input must conform to `request.schema.json`. Invalid → HTTP 400 with error list.
- Output conforms to `response.schema.json`. Missing fields → contract violation.

## Idempotency
- Same inputs (including seeds) → bitwise-identical normalized outputs.

## Performance SLOs (local-first)
- P95 latency ≤ 2000 ms for batch of ≤ 50 probes.
- Throughput ≥ 50 eval/min sustained.

## Error Taxonomy
- E-SCHEMA-REQ, E-TIMEOUT, E-PROVIDER, E-RATE-LIMIT, E-TOOL-MISMATCH, E-SERVER.

## Rate Limiting
- 60 r/min per API key; burst 10 r/s; 429 with `Retry-After`.

## Backoff & Retries
- Idempotent operations only; exponential backoff; jitter; max 3 retries.

## Monitoring
- Export metrics named in observability doc; JSON logs; OTel traces.
```

---

### **13.5 Acceptance Tests —**

### **docs/lifecycle/2-design/<FEATURE>_acceptance.yaml**

```
version: "1.0.0"
feature_id: "<FEATURE>"
tests:
  - id: "A1"
    description: "Happy path — controlled probe batch"
    request_ref: "./<FEATURE>_schemas/request.schema.json"
    expected:
      http: 200
      schema_ref: "./<FEATURE>_schemas/response.schema.json"
      metrics:
        reproducibility_rate:
          op: ">="
          value: 0.95
  - id: "A2"
    description: "Invalid request schema"
    mutate: "drop:probes[0].expected"
    expected:
      http: 400
  - id: "A3"
    description: "Rate limit response"
    setup: "simulate:rate_limit"
    expected:
      http: 429
  - id: "A4"
    description: "Determinism — same inputs produce identical normalized outputs"
    repeat: 2
    expected:
      by_probe_identical: true
```

---

### **13.6 Security —**

### **docs/lifecycle/2-design/<FEATURE>_security.md**

```
# Security & Privacy — <FEATURE>
version: 1.0.0

## AuthN/Z
- API key in `X-API-Key`. RBAC roles: runner, reader, admin.
- Deny by default; no wildcard origins unless dev mode.

## Input/Output Handling
- JSON Schema validation at ingress and egress.
- Redact secrets from logs (args fields like token, api_key).

## Network & Rate Limits
- 15s upstream timeout; circuit-breaker on consecutive failures.
- 60 r/min, 10 r/s burst per key.

## Data Retention
- Keep metrics only; discard raw generations unless explicitly enabled.
- TTL 14 days for run logs (configurable).

## Compliance
- Licenses recorded; no PII; provider ToS respected.
```

---

### **13.7 Observability —**

### **docs/lifecycle/2-design/<FEATURE>_observability.md**

```
# Observability — <FEATURE>
version: 1.0.0

## Metrics
- eval_requests_total{feature,model}
- eval_request_duration_ms_bucket{feature}
- reproducibility_rate{feature,model}
- robustness_delta{feature,model}
- errors_total{feature,error_class}

## Logs (JSONL)
Fields: ts, level, feature_id, probe_id, model_id, provider, seed, dataset_version, commit_sha, elapsed_ms, status, error_class

## Traces
Spans: eval.request, eval.model_call, eval.score
```

---

### **13.8 FMEA —**

### **docs/lifecycle/2-design/<FEATURE>_fmea.md**

```
# FMEA — <FEATURE>
version: 1.0.0

| Failure Mode         | Cause                 | Effect                     | Detect                    | Mitigation                          | Owner | Sev | Occ | Det | RPN |
|----------------------|-----------------------|----------------------------|---------------------------|-------------------------------------|-------|-----|-----|-----|-----|
| Provider timeout     | Network/latency       | Partial/incomplete results | Timeout counters, traces  | Retries w/ backoff, 202+poll token  | Eng   | 7   | 4   | 3   | 84  |
| Schema invalid input | Client bug            | 400 errors                 | Schema validator metrics  | Client SDK + examples, clear errors | Eng   | 4   | 5   | 2   | 40  |
| Tool mismatch        | Model formatting      | Low fidelity score         | Scorer error taxonomy     | Canonicalization, stricter prompts  | Res   | 5   | 3   | 4   | 60  |
```

---

### **13.9 Scalability —**

### **docs/lifecycle/2-design/<FEATURE>_scalability.md**

```
# Scalability Envelope — <FEATURE>
version: 1.0.0

- QPS: 50 eval/min local; target 200+ in CI farm.
- Concurrency: 8 (local), 32 (CI runners).
- Payload limits: req ≤ 32 KB; resp ≤ 64 KB.
- Timeouts: upstream 15s; total 20s P95.
- Memory: ≤ 512 MB per worker.
```

---

### **13.10 Design Review Checklist —**

### **docs/lifecycle/2-design/<FEATURE>_review_checklist.md**

```
# Review Checklist — M2 <FEATURE>
- [ ] System design complete; diagrams present
- [ ] OpenAPI lints clean (Spectral)
- [ ] JSON Schemas validate (ajv)
- [ ] Contracts define SLOs, error taxonomy, idempotency
- [ ] Acceptance tests load and reference schemas
- [ ] Security doc covers auth, redaction, rate limits
- [ ] Observability doc defines metrics/logs/traces
- [ ] FMEA present with owners and mitigations
- [ ] Scalability envelope defined
- [ ] Crosslinks to M0/M1 present
- [ ] CI workflow added and green
```

---

### **13.11 Decision Log —**

### **docs/lifecycle/2-design/<FEATURE>_decision_log.md**

```
# Decision Log — M2 <FEATURE>
## DD-0001: HTTP JSON vs gRPC
- Context: local-first simplicity
- Decision: HTTP JSON v1
- Rationale: fewer deps, easier to test
- Date/Owner: <YYYY-MM-DD>/<name>
```

---

## **14) CI/CD wiring (GitHub Actions)**

**File:** .github/workflows/m2-design-validate.yml

```
name: M2 Design Validation
on:
  pull_request:
    paths:
      - "docs/lifecycle/2-design/**"
      - "docs/templates/**"
jobs:
  validate:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Setup node & python
        uses: actions/setup-node@v4
        with: { node-version: "22" }
      - uses: actions/setup-python@v5
        with: { python-version: "3.12" }

      - name: Install linters
        run: |
          npm i -g @stoplight/spectral-cli@6 ajv-cli@5
          pipx install markdownlint-cli
          sudo apt-get update && sudo apt-get install -y jq

      - name: Lint Markdown
        run: markdownlint "docs/**/*.md" || true

      - name: Lint OpenAPI with Spectral
        run: spectral lint docs/lifecycle/2-design/*_openapi.yaml

      - name: Validate JSON Schemas (self-parse)
        run: |
          for f in docs/lifecycle/2-design/*_schemas/*.schema.json; do
            ajv compile -s "$f"
          done

      - name: Validate Acceptance Spec references
        run: |
          test -f docs/lifecycle/2-design/*_acceptance.yaml
          echo "Acceptance spec present"
```

**PR template additions** — .github/pull_request_template.md

```
## M2 Design Checklist for <FEATURE>
- [ ] System design + diagrams
- [ ] OpenAPI passes Spectral lint
- [ ] JSON Schemas validated
- [ ] Interface contracts complete (SLOs, errors, idempotency)
- [ ] Acceptance tests defined and reference schemas
- [ ] Security, Observability, FMEA, Scalability docs present
- [ ] Crosslinks to M0/M1
- [ ] CI green

Reviewers: @engineering @qa @research
```

**CODEOWNERS** additions

```
docs/lifecycle/2-design/ @engineering @qa @research
```

---

## **15) Worked example (FEATURE =**

## **tool_use_fidelity**

## **)**

Use these concrete variants.

### **OpenAPI (endpoint names)**

- POST /tool-use/evaluate

### **Request schema adjustments**

- expected.tool enum: ["weather.get_forecast","calendar.create_event"]

- expected.args schemas:

  - weather.get_forecast: { city: string, date: string }

  - calendar.create_event: { title: string, date: string, time: string }

### **snippet —**

### **request.schema.json**

###  **fragment**

```
"expected": {
  "type": "object",
  "required": ["tool", "args"],
  "properties": {
    "tool": {
      "type": "string",
      "enum": ["weather.get_forecast", "calendar.create_event"]
    },
    "args": {
      "oneOf": [
        {
          "type": "object",
          "required": ["city", "date"],
          "properties": {
            "city": { "type": "string" },
            "date": { "type": "string", "pattern": "^\\d{4}-\\d{2}-\\d{2}$" }
          },
          "additionalProperties": false
        },
        {
          "type": "object",
          "required": ["title", "date", "time"],
          "properties": {
            "title": { "type": "string" },
            "date": { "type": "string", "pattern": "^\\d{4}-\\d{2}-\\d{2}$" },
            "time": { "type": "string", "pattern": "^\\d{2}:\\d{2}$" }
          },
          "additionalProperties": false
        }
      ]
    }
  },
  "additionalProperties": false
}
```

### **Acceptance test example**

```
tests:
  - id: "A1"
    description: "Correct tool-call batch"
    expected:
      http: 200
      metrics:
        reproducibility_rate: { op: ">=", value: 0.95 }
```

### **Contracts specifics**

- Error E-TOOL-MISMATCH raised if predicted.tool != expected.tool or args fail schema.

- Determinism proof: normalized JSON of predicted calls hashed; hashes equal across repeats.

---

## **16) Exit criteria (hard)**

- All eleven deliverables present and complete.

- Spectral and ajv validations green. Acceptance spec loads.

- Security, observability, FMEA, scalability docs present and reviewed.

- Crosslinks to M0/M1 valid. PR approved by Eng + QA (+ Research).

- Tag design-<FEATURE>-approved created. Issue status: **Ready for M3**.

Delivering final **M2 files** for **tool_use_fidelity**. Copy into your repo as shown.

---

### **docs/lifecycle/2-design/tool_use_fidelity_design.md**

````
# System Design — tool_use_fidelity
version: 1.0.0

## Context & Goals
- M0 intake: ../0-intake/tool_use_fidelity_intake.md
- M1 eval design: ../1-research/tool_use_fidelity_eval_design.md
- Hypotheses: ../1-research/tool_use_fidelity_hypotheses.yaml
- Baseline: ../1-research/tool_use_fidelity_baseline.json

Goal: evaluate deterministic function-calling fidelity under controlled and adversarial probes with strict JSON validation and reproducible runs.

## Architecture
```mermaid
flowchart TD
    C[Client] -->|HTTP JSON| API[/tool-use/evaluate/]
    API --> VAL[JSON Schema Validator]
    API --> EXEC[Executor]
    EXEC --> OR[OpenRouter Connector]
    EXEC --> SC[Scorer]
    SC --> MET[Metrics Store]
    API --> RS[Results Store]
    subgraph Observability
      MET --> PRM[Prometheus]
      API --> LOG[JSON Logs]
      API --> OTL[OpenTelemetry Traces]
    end
````

## **Data Flow**

1. Client POSTs probes batch → schema validate.

2. Executor iterates probes with fixed seeds and decoding.

3. Connector calls provider. Output normalized and validated.

4. Scorer computes metrics and error taxonomy.

5. Store metrics, logs, and trace spans. Return JSON response.

## **Components**

- API: FastAPI.

- Validation: AJV-compatible JSON Schema.

- Executor: synchronous, idempotent, fixed seeds {1..5}.

- Scorer: exact-match on normalized tool calls; latency capture; robustness delta.

- Storage: SQLite for results, Prometheus for metrics.

- Observability: JSON logs + OTel traces.

## **Alternatives**

- gRPC vs HTTP: HTTP chosen for local-first simplicity.

- Async queue vs sync: sync chosen for determinism and simpler CI.

## **Chosen Approach**

- Single endpoint /tool-use/evaluate.

- Externalized JSON Schemas under tool_use_fidelity_schemas/.

- Contract tests fed from tool_use_fidelity_acceptance.yaml.

## **Risks & Mitigation**

- Provider latency variance → timeouts, retries, P95 tracking.

- Schema drift → versioned $id, CI schema compilation.

- Non-determinism → fixed seeds, temperature=0, normalized comparison.

````
---

### `docs/lifecycle/2-design/tool_use_fidelity_openapi.yaml`
```yaml
openapi: 3.1.0
info:
  title: tool_use_fidelity Evaluation API
  version: 1.0.0
servers:
  - url: /api
paths:
  /tool-use/evaluate:
    post:
      summary: Evaluate tool-use fidelity on a batch of probes
      operationId: evaluateToolUseFidelity
      security:
        - ApiKeyAuth: []
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: "./tool_use_fidelity_schemas/request.schema.json"
      responses:
        "200":
          description: Evaluation results
          content:
            application/json:
              schema:
                $ref: "./tool_use_fidelity_schemas/response.schema.json"
        "400":
          description: Request failed schema validation
        "401":
          description: Unauthorized
        "429":
          description: Rate limited
        "500":
          description: Internal error
components:
  securitySchemes:
    ApiKeyAuth:
      type: apiKey
      in: header
      name: X-API-Key
````

---

### **docs/lifecycle/2-design/tool_use_fidelity_schemas/request.schema.json**

```
{
  "$id": "https://neoprompt.local/schemas/tool_use_fidelity/request.schema.json",
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "title": "tool_use_fidelity Request",
  "type": "object",
  "required": ["feature_id", "probes", "config"],
  "properties": {
    "feature_id": { "type": "string", "const": "tool_use_fidelity" },
    "probes": {
      "type": "array",
      "minItems": 1,
      "items": {
        "type": "object",
        "required": ["id", "prompt", "expected"],
        "properties": {
          "id": { "type": "string", "minLength": 1 },
          "prompt": { "type": "string", "minLength": 1 },
          "expected": {
            "type": "object",
            "required": ["tool", "args"],
            "properties": {
              "tool": {
                "type": "string",
                "enum": ["weather.get_forecast", "calendar.create_event"]
              },
              "args": {
                "oneOf": [
                  {
                    "type": "object",
                    "required": ["city", "date"],
                    "properties": {
                      "city": { "type": "string", "minLength": 1 },
                      "date": { "type": "string", "pattern": "^\\d{4}-\\d{2}-\\d{2}$" }
                    },
                    "additionalProperties": false
                  },
                  {
                    "type": "object",
                    "required": ["title", "date", "time"],
                    "properties": {
                      "title": { "type": "string", "minLength": 1 },
                      "date": { "type": "string", "pattern": "^\\d{4}-\\d{2}-\\d{2}$" },
                      "time": { "type": "string", "pattern": "^\\d{2}:\\d{2}$" }
                    },
                    "additionalProperties": false
                  }
                ]
              }
            },
            "additionalProperties": false
          }
        },
        "additionalProperties": false
      }
    },
    "config": {
      "type": "object",
      "required": ["model_id", "provider", "seeds", "decoding"],
      "properties": {
        "model_id": { "type": "string", "minLength": 1 },
        "provider": { "type": "string", "const": "openrouter" },
        "seeds": {
          "type": "array",
          "minItems": 1,
          "items": { "type": "integer" }
        },
        "decoding": {
          "type": "object",
          "required": ["temperature", "top_p"],
          "properties": {
            "temperature": { "type": "number", "const": 0 },
            "top_p": { "type": "number", "const": 1 }
          },
          "additionalProperties": false
        }
      },
      "additionalProperties": false
    }
  },
  "additionalProperties": false
}
```

---

### **docs/lifecycle/2-design/tool_use_fidelity_schemas/response.schema.json**

```
{
  "$id": "https://neoprompt.local/schemas/tool_use_fidelity/response.schema.json",
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "title": "tool_use_fidelity Response",
  "type": "object",
  "required": ["feature_id", "model_id", "metrics", "by_probe"],
  "properties": {
    "feature_id": { "type": "string", "const": "tool_use_fidelity" },
    "model_id": { "type": "string" },
    "metrics": {
      "type": "object",
      "required": ["reproducibility_rate", "latency_p95_ms"],
      "properties": {
        "reproducibility_rate": { "type": "number", "minimum": 0, "maximum": 1 },
        "robustness_delta": { "type": "number" },
        "latency_p95_ms": { "type": "number", "minimum": 0 }
      },
      "additionalProperties": true
    },
    "by_probe": {
      "type": "array",
      "items": {
        "type": "object",
        "required": ["id", "status", "elapsed_ms"],
        "properties": {
          "id": { "type": "string" },
          "status": { "type": "string", "enum": ["ok", "error"] },
          "elapsed_ms": { "type": "number", "minimum": 0 },
          "error_class": { "type": "string" }
        },
        "additionalProperties": false
      }
    }
  },
  "additionalProperties": false
}
```

---

### **docs/lifecycle/2-design/tool_use_fidelity_schemas/event.schema.json**

```
{
  "$id": "https://neoprompt.local/schemas/tool_use_fidelity/event.schema.json",
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "title": "tool_use_fidelity Event",
  "type": "object",
  "required": ["ts", "feature_id", "event", "payload"],
  "properties": {
    "ts": { "type": "string" },
    "feature_id": { "type": "string", "const": "tool_use_fidelity" },
    "event": { "type": "string", "enum": ["eval.request", "eval.model_call", "eval.score"] },
    "payload": { "type": "object" }
  },
  "additionalProperties": false
}
```

---

### **docs/lifecycle/2-design/tool_use_fidelity_contracts.md**

```
# Interface Contracts — tool_use_fidelity
version: 1.0.0

## Functional
- Input must match request.schema.json; invalid → HTTP 400 with error list.
- Output matches response.schema.json.

## Idempotency
- Same inputs (including seeds and decoding) → identical normalized outputs.

## SLOs
- P95 latency ≤ 2000 ms for ≤ 50 probes.
- Throughput ≥ 50 eval/min local.

## Error Taxonomy
- E-SCHEMA-REQ, E-TIMEOUT, E-PROVIDER, E-RATE-LIMIT, E-TOOL-MISMATCH, E-SERVER.

## Rate Limiting
- 60 requests/min per API key; 10 req/s burst; respond 429 with Retry-After.

## Retries
- Idempotent only; exponential backoff with jitter; max 3; cap 30s.

## Monitoring
- Metrics and logs as defined in observability doc; OTel traces enabled.
```

---

### **docs/lifecycle/2-design/tool_use_fidelity_acceptance.yaml**

```
version: "1.0.0"
feature_id: "tool_use_fidelity"
tests:
  - id: "A1"
    description: "Happy path — controlled probe batch"
    request_example: "./examples/request_A1.json"
    expected:
      http: 200
      schema_ref: "./tool_use_fidelity_schemas/response.schema.json"
      metrics:
        reproducibility_rate: { op: ">=", value: 0.95 }
  - id: "A2"
    description: "Invalid request schema"
    request_example: "./examples/request_A2_invalid.json"
    expected:
      http: 400
  - id: "A3"
    description: "Rate limited"
    setup: "simulate:rate_limit"
    expected:
      http: 429
  - id: "A4"
    description: "Determinism — same inputs identical normalized outputs"
    request_example: "./examples/request_A1.json"
    repeat: 2
    expected:
      by_probe_identical: true
```

---

### **docs/lifecycle/2-design/tool_use_fidelity_security.md**

```
# Security & Privacy — tool_use_fidelity
version: 1.0.0

## AuthN/Z
- X-API-Key required. Roles: runner (POST), reader (metrics), admin (config).
- CORS: dev wildcard allowed, prod explicit allowlist.

## Validation & Redaction
- Ingress and egress JSON Schema validation.
- Redact fields named: token, api_key, password in logs.

## Network Controls
- Upstream timeout 15s; circuit-breaker on ≥5 consecutive failures; cool-off 60s.
- Rate limits 60/min and 10/s burst per key.

## Secrets
- Stored in environment or Vault; never in VCS.

## Retention
- Metrics retained; raw generations off by default. Run logs TTL 14d.
```

---

### **docs/lifecycle/2-design/tool_use_fidelity_observability.md**

```
# Observability — tool_use_fidelity
version: 1.0.0

## Metrics (Prometheus)
- eval_requests_total{feature,model}
- eval_request_duration_ms_bucket{feature} (buckets: 100,250,500,1000,1500,2000,3000,5000)
- reproducibility_rate{feature,model}
- robustness_delta{feature,model}
- errors_total{feature,error_class}

## Logs (JSONL)
Fields: ts, level, feature_id, probe_id, model_id, provider, seed, dataset_version, commit_sha, elapsed_ms, status, error_class

## Traces (OTel)
Spans: eval.request, eval.model_call, eval.score
Attributes mirror log fields.
```

---

### **docs/lifecycle/2-design/tool_use_fidelity_fmea.md**

```
# FMEA — tool_use_fidelity
version: 1.0.0

| Failure Mode         | Cause               | Effect                       | Detect                      | Mitigation                          | Owner | Sev | Occ | Det | RPN |
|----------------------|---------------------|------------------------------|-----------------------------|-------------------------------------|-------|-----|-----|-----|-----|
| Provider timeout     | Network/latency     | Incomplete run               | Timeout metrics, traces     | Retries+backoff; 202+poll optional  | Eng   | 7   | 4   | 3   | 84  |
| Schema invalid input | Client mistakes     | 400 responses                | Validator counters          | SDK examples; clear error messages  | Eng   | 4   | 5   | 2   | 40  |
| Tool mismatch        | Model formatting    | Lower fidelity metric        | Scorer taxonomy             | Canonicalization; stricter prompts  | Res   | 6   | 3   | 4   | 72  |
| Rate limited         | Abuse/high QPS      | Throttled requests           | 429 count                   | Per-key limits; Retry-After hints   | Eng   | 3   | 5   | 2   | 30  |
| Storage unavailable  | FS/DB issues        | Metrics not persisted        | Error logs, health checks   | Local queue; retry; alert           | Ops   | 5   | 2   | 3   | 30  |
```

---

### **docs/lifecycle/2-design/tool_use_fidelity_scalability.md**

```
# Scalability Envelope — tool_use_fidelity
version: 1.0.0

- QPS: 50 eval/min local; 200+ in CI farm.
- Concurrency: 8 local, 32 CI.
- Payload limits: request ≤ 32 KB; response ≤ 64 KB.
- Timeouts: upstream 15s; total 20s P95.
- Memory cap: 512 MB per worker; CPU target: ≤ 1 core per 50 eval/min.
```

---

### **docs/lifecycle/2-design/tool_use_fidelity_review_checklist.md**

```
# Review Checklist — M2 tool_use_fidelity
- [ ] System design + diagram present
- [ ] OpenAPI passes Spectral
- [ ] JSON Schemas compile with ajv
- [ ] Contracts define SLOs, errors, idempotency
- [ ] Acceptance tests reference valid examples
- [ ] Security doc complete
- [ ] Observability doc lists metrics/logs/traces
- [ ] FMEA with owners and RPNs
- [ ] Scalability envelope numeric
- [ ] Crosslinks to M0/M1 present
- [ ] CI workflow added and green
```

---

### **docs/lifecycle/2-design/tool_use_fidelity_decision_log.md**

```
# Decision Log — M2 tool_use_fidelity
## DD-0001: Transport protocol
- Decision: HTTP JSON v1
- Alternatives: gRPC
- Rationale: simpler dev; easier local CI
- Date/Owner: 2025-10-03 / Eng Lead

## DD-0002: Determinism policy
- Decision: fixed seeds, temperature=0, top_p=1, normalized JSON compare
- Alternatives: temperature>0 with averaging
- Rationale: deterministic CI; simple scoring
```

---

### **Examples for acceptance tests**

#### **docs/lifecycle/2-design/examples/request_A1.json**

```
{
  "feature_id": "tool_use_fidelity",
  "probes": [
    {
      "id": "p001",
      "prompt": "Call weather.get_forecast for city='Paris' and date='2025-10-05'.",
      "expected": { "tool": "weather.get_forecast", "args": { "city": "Paris", "date": "2025-10-05" } }
    },
    {
      "id": "p002",
      "prompt": "Create a calendar event titled 'Team Sync' on 2025-10-06 at 14:00.",
      "expected": { "tool": "calendar.create_event", "args": { "title": "Team Sync", "date": "2025-10-06", "time": "14:00" } }
    }
  ],
  "config": {
    "model_id": "qwen-2.5-instruct",
    "provider": "openrouter",
    "seeds": [1,2,3,4,5],
    "decoding": { "temperature": 0, "top_p": 1 }
  }
}
```

#### **docs/lifecycle/2-design/examples/request_A2_invalid.json**

```
{
  "feature_id": "tool_use_fidelity",
  "probes": [
    {
      "id": "p001",
      "prompt": "Missing expected field causes 400"
    }
  ],
  "config": {
    "model_id": "qwen-2.5-instruct",
    "provider": "openrouter",
    "seeds": [1],
    "decoding": { "temperature": 0, "top_p": 1 }
  }
}
```

---

### **.spectral.yaml**

###  **(repo root)**

```
extends: ["spectral:oas"]
rules:
  info-contact: off
  operation-operationId: warn
  no-unused-components: warn
```

---

### **.github/workflows/m2-design-validate.yml**

```
name: M2 Design Validation
on:
  pull_request:
    paths:
      - "docs/lifecycle/2-design/**"
      - "docs/templates/**"
      - ".spectral.yaml"
jobs:
  validate:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with: { node-version: "22" }
      - uses: actions/setup-python@v5
        with: { python-version: "3.12" }
      - name: Install linters
        run: |
          npm i -g @stoplight/spectral-cli@6 ajv-cli@5
          pipx install markdownlint-cli
          sudo apt-get update && sudo apt-get install -y jq
      - name: Lint Markdown
        run: markdownlint "docs/**/*.md" || true
      - name: Lint OpenAPI
        run: spectral lint docs/lifecycle/2-design/tool_use_fidelity_openapi.yaml
      - name: Compile JSON Schemas
        run: |
          for f in docs/lifecycle/2-design/tool_use_fidelity_schemas/*.schema.json; do
            ajv compile -s "$f"
          done
      - name: Check acceptance spec presence
        run: test -f docs/lifecycle/2-design/tool_use_fidelity_acceptance.yaml
```

---

### **CODEOWNERS**

###  **additions**

```
docs/lifecycle/2-design/ @engineering @qa @research
```

---

### **PR template additions**

```
## M2 Design Checklist — tool_use_fidelity
- [ ] Design doc + diagram complete
- [ ] OpenAPI passes Spectral
- [ ] JSON Schemas compile
- [ ] Contracts (SLOs, idempotency, errors) complete
- [ ] Acceptance tests + examples present
- [ ] Security, Observability, FMEA, Scalability docs present
- [ ] Crosslinks to M0/M1
- [ ] CI green

Reviewers: @engineering @qa @research
```
